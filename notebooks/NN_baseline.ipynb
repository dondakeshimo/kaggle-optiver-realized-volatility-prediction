{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c23b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_rows', 300)\n",
    "pd.set_option('max_columns', 300)\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa4534b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = '../input/optiver-realized-volatility-prediction/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f9b2a",
   "metadata": {},
   "source": [
    "## Functions for preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05b693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])/(df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2'])/(df['bid_size2'] + df['ask_size2'])\n",
    "    return wap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa57fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13348a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7bf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75691393",
   "metadata": {},
   "source": [
    "## Main function for preprocessing book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec214961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_book(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    #calculate return etc\n",
    "    df['wap'] = calc_wap(df)\n",
    "    df['log_return'] = df.groupby('time_id')['wap'].apply(log_return)\n",
    "    \n",
    "    df['wap2'] = calc_wap2(df)\n",
    "    df['log_return2'] = df.groupby('time_id')['wap2'].apply(log_return)\n",
    "    \n",
    "    df['wap_balance'] = abs(df['wap'] - df['wap2'])\n",
    "    \n",
    "    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1'])/2)\n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "\n",
    "    #dict for aggregate\n",
    "    create_feature_dict = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'log_return2':[realized_volatility],\n",
    "        'wap_balance':[np.mean],\n",
    "        'price_spread':[np.mean],\n",
    "        'bid_spread':[np.mean],\n",
    "        'ask_spread':[np.mean],\n",
    "        'volume_imbalance':[np.mean],\n",
    "        'total_volume':[np.mean],\n",
    "        'wap':[np.mean],\n",
    "            }\n",
    "\n",
    "    #####groupby / all seconds\n",
    "    df_feature = pd.DataFrame(df.groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns] #time_id is changed to time_id_\n",
    "        \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second \n",
    "    \n",
    "        df_feature_sec = pd.DataFrame(df.query(f'seconds_in_bucket >= {second}').groupby(['time_id']).agg(create_feature_dict)).reset_index()\n",
    "\n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns] #time_id is changed to time_id_\n",
    "     \n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "\n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    #create row_id\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4810a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.03 s, sys: 71.3 ms, total: 5.1 s\n",
      "Wall time: 5.04 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>log_return_realized_volatility_300</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>197.144781</td>\n",
       "      <td>374.235690</td>\n",
       "      <td>0.997938</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>233.946667</td>\n",
       "      <td>350.560000</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>233.781553</td>\n",
       "      <td>621.131068</td>\n",
       "      <td>1.000310</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>257.920000</td>\n",
       "      <td>668.640000</td>\n",
       "      <td>1.000682</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>115.829787</td>\n",
       "      <td>343.734043</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>105.432692</td>\n",
       "      <td>326.759615</td>\n",
       "      <td>1.000111</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>132.074919</td>\n",
       "      <td>385.429967</td>\n",
       "      <td>1.002357</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>123.423313</td>\n",
       "      <td>394.588957</td>\n",
       "      <td>1.002277</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>165.754386</td>\n",
       "      <td>533.543860</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>138.587719</td>\n",
       "      <td>460.429825</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_return_realized_volatility  log_return2_realized_volatility  \\\n",
       "0                           0.004499                         0.006999   \n",
       "1                           0.001204                         0.002476   \n",
       "2                           0.002369                         0.004801   \n",
       "3                           0.002574                         0.003637   \n",
       "4                           0.001894                         0.003257   \n",
       "...                              ...                              ...   \n",
       "3825                        0.002579                         0.003821   \n",
       "3826                        0.002206                         0.002847   \n",
       "3827                        0.002913                         0.003266   \n",
       "3828                        0.003046                         0.005105   \n",
       "3829                        0.001901                         0.002541   \n",
       "\n",
       "      wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0             0.000388           0.000852         0.000176        -0.000151   \n",
       "1             0.000212           0.000394         0.000142        -0.000135   \n",
       "2             0.000331           0.000725         0.000197        -0.000198   \n",
       "3             0.000380           0.000860         0.000190        -0.000108   \n",
       "4             0.000254           0.000397         0.000191        -0.000109   \n",
       "...                ...                ...              ...              ...   \n",
       "3825          0.000212           0.000552         0.000083        -0.000182   \n",
       "3826          0.000267           0.000542         0.000092        -0.000172   \n",
       "3827          0.000237           0.000525         0.000202        -0.000083   \n",
       "3828          0.000245           0.000480         0.000113        -0.000166   \n",
       "3829          0.000177           0.000458         0.000124        -0.000127   \n",
       "\n",
       "      volume_imbalance_mean  total_volume_mean  wap_mean  \\\n",
       "0                134.894040         323.496689  1.003725   \n",
       "1                142.050000         411.450000  1.000239   \n",
       "2                141.414894         416.351064  0.999542   \n",
       "3                146.216667         435.266667  0.998832   \n",
       "4                123.846591         343.221591  0.999619   \n",
       "...                     ...                ...       ...   \n",
       "3825             197.144781         374.235690  0.997938   \n",
       "3826             233.781553         621.131068  1.000310   \n",
       "3827             115.829787         343.734043  0.999552   \n",
       "3828             132.074919         385.429967  1.002357   \n",
       "3829             165.754386         533.543860  0.999123   \n",
       "\n",
       "      log_return_realized_volatility_300  log_return2_realized_volatility_300  \\\n",
       "0                               0.002953                             0.004864   \n",
       "1                               0.000981                             0.002009   \n",
       "2                               0.001295                             0.003196   \n",
       "3                               0.001776                             0.002713   \n",
       "4                               0.001520                             0.002188   \n",
       "...                                  ...                                  ...   \n",
       "3825                            0.001673                             0.002573   \n",
       "3826                            0.001487                             0.002255   \n",
       "3827                            0.001928                             0.002646   \n",
       "3828                            0.002137                             0.003934   \n",
       "3829                            0.001507                             0.001517   \n",
       "\n",
       "      wap_balance_mean_300  price_spread_mean_300  bid_spread_mean_300  \\\n",
       "0                 0.000372               0.000822             0.000223   \n",
       "1                 0.000239               0.000353             0.000164   \n",
       "2                 0.000431               0.000689             0.000141   \n",
       "3                 0.000331               0.000833             0.000158   \n",
       "4                 0.000252               0.000425             0.000191   \n",
       "...                    ...                    ...                  ...   \n",
       "3825              0.000193               0.000509             0.000062   \n",
       "3826              0.000300               0.000588             0.000074   \n",
       "3827              0.000216               0.000446             0.000191   \n",
       "3828              0.000269               0.000516             0.000096   \n",
       "3829              0.000142               0.000432             0.000140   \n",
       "\n",
       "      ask_spread_mean_300  volume_imbalance_mean_300  total_volume_mean_300  \\\n",
       "0               -0.000162                 137.158273             294.928058   \n",
       "1               -0.000123                 135.513043             484.521739   \n",
       "2               -0.000249                 144.147059             455.235294   \n",
       "3               -0.000095                 144.698113             418.169811   \n",
       "4               -0.000120                  99.449438             407.584270   \n",
       "...                   ...                        ...                    ...   \n",
       "3825            -0.000169                 233.946667             350.560000   \n",
       "3826            -0.000177                 257.920000             668.640000   \n",
       "3827            -0.000075                 105.432692             326.759615   \n",
       "3828            -0.000175                 123.423313             394.588957   \n",
       "3829            -0.000114                 138.587719             460.429825   \n",
       "\n",
       "      wap_mean_300   row_id  \n",
       "0         1.003753      0-5  \n",
       "1         1.000397     0-11  \n",
       "2         0.998685     0-16  \n",
       "3         0.998436     0-31  \n",
       "4         0.999488     0-62  \n",
       "...            ...      ...  \n",
       "3825      0.997519  0-32751  \n",
       "3826      1.000682  0-32753  \n",
       "3827      1.000111  0-32758  \n",
       "3828      1.002277  0-32763  \n",
       "3829      0.998454  0-32767  \n",
       "\n",
       "[3830 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"book_train.parquet/stock_id=0\"\n",
    "preprocessor_book(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67edbac",
   "metadata": {},
   "source": [
    "## Main function for preprocessing trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476faddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_trade(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    \n",
    "    \n",
    "    aggregate_dictionary = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "    \n",
    "    df_feature = df.groupby('time_id').agg(aggregate_dictionary)\n",
    "    \n",
    "    df_feature = df_feature.reset_index()\n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "\n",
    "    \n",
    "    ######groupby / last XX seconds\n",
    "    last_seconds = [300]\n",
    "    \n",
    "    for second in last_seconds:\n",
    "        second = 600 - second\n",
    "    \n",
    "        df_feature_sec = df.query(f'seconds_in_bucket >= {second}').groupby('time_id').agg(aggregate_dictionary)\n",
    "        df_feature_sec = df_feature_sec.reset_index()\n",
    "        \n",
    "        df_feature_sec.columns = ['_'.join(col) for col in df_feature_sec.columns]\n",
    "        df_feature_sec = df_feature_sec.add_suffix('_' + str(second))\n",
    "        \n",
    "        df_feature = pd.merge(df_feature,df_feature_sec,how='left',left_on='time_id_',right_on=f'time_id__{second}')\n",
    "        df_feature = df_feature.drop([f'time_id__{second}'],axis=1)\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['trade_time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b57a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 s, sys: 9.13 ms, total: 2.58 s\n",
      "Wall time: 2.56 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.001519</td>\n",
       "      <td>52</td>\n",
       "      <td>3450</td>\n",
       "      <td>3.057692</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2365.0</td>\n",
       "      <td>3.257143</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>28</td>\n",
       "      <td>4547</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.001521</td>\n",
       "      <td>36</td>\n",
       "      <td>4250</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2294.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.001794</td>\n",
       "      <td>53</td>\n",
       "      <td>3217</td>\n",
       "      <td>2.150943</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>29</td>\n",
       "      <td>3679</td>\n",
       "      <td>2.413793</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trade_log_return_realized_volatility  \\\n",
       "0                                 0.002006   \n",
       "1                                 0.000901   \n",
       "2                                 0.001961   \n",
       "3                                 0.001561   \n",
       "4                                 0.000871   \n",
       "...                                    ...   \n",
       "3825                              0.001519   \n",
       "3826                              0.001411   \n",
       "3827                              0.001521   \n",
       "3828                              0.001794   \n",
       "3829                              0.001197   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40            3179   \n",
       "1                                       30            1289   \n",
       "2                                       25            2161   \n",
       "3                                       15            1962   \n",
       "4                                       22            1791   \n",
       "...                                    ...             ...   \n",
       "3825                                    52            3450   \n",
       "3826                                    28            4547   \n",
       "3827                                    36            4250   \n",
       "3828                                    53            3217   \n",
       "3829                                    29            3679   \n",
       "\n",
       "      trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                   2.750000                                  0.001308   \n",
       "1                   1.900000                                  0.000587   \n",
       "2                   2.720000                                  0.001137   \n",
       "3                   3.933333                                  0.001089   \n",
       "4                   4.045455                                  0.000453   \n",
       "...                      ...                                       ...   \n",
       "3825                3.057692                                  0.001162   \n",
       "3826                3.892857                                  0.001066   \n",
       "3827                3.500000                                  0.001242   \n",
       "3828                2.150943                                  0.001404   \n",
       "3829                2.413793                                  0.000801   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                         21.0              1587.0   \n",
       "1                                         16.0               900.0   \n",
       "2                                         12.0              1189.0   \n",
       "3                                          9.0              1556.0   \n",
       "4                                         11.0              1219.0   \n",
       "...                                        ...                 ...   \n",
       "3825                                      35.0              2365.0   \n",
       "3826                                      12.0              2161.0   \n",
       "3827                                      22.0              2294.0   \n",
       "3828                                      25.0              1627.0   \n",
       "3829                                      16.0              2650.0   \n",
       "\n",
       "      trade_order_count_mean_300   row_id  \n",
       "0                       2.571429      0-5  \n",
       "1                       2.250000     0-11  \n",
       "2                       3.166667     0-16  \n",
       "3                       5.111111     0-31  \n",
       "4                       4.909091     0-62  \n",
       "...                          ...      ...  \n",
       "3825                    3.257143  0-32751  \n",
       "3826                    4.250000  0-32753  \n",
       "3827                    3.727273  0-32758  \n",
       "3828                    1.920000  0-32763  \n",
       "3829                    3.000000  0-32767  \n",
       "\n",
       "[3830 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"trade_train.parquet/stock_id=0\"\n",
    "preprocessor_trade(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f102b56b",
   "metadata": {},
   "source": [
    "## Combined preprocessor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3d3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    from joblib import Parallel, delayed # parallel computing to save time\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def for_joblib(stock_id):\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "            \n",
    "        df_tmp = pd.merge(preprocessor_book(file_path_book),preprocessor_trade(file_path_trade),on='row_id',how='left')\n",
    "     \n",
    "        return pd.concat([df,df_tmp])\n",
    "    \n",
    "    df = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(for_joblib)(stock_id) for stock_id in list_stock_ids\n",
    "        )\n",
    "\n",
    "    df =  pd.concat(df,ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc051c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>log_return_realized_volatility_300</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>row_id</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0-11</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>125.013029</td>\n",
       "      <td>296.185668</td>\n",
       "      <td>1.000142</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>120.469231</td>\n",
       "      <td>322.284615</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>1-32751</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>49</td>\n",
       "      <td>3249</td>\n",
       "      <td>2.775510</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>3.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.012168</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>254.006073</td>\n",
       "      <td>567.840081</td>\n",
       "      <td>1.007503</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>217.410788</td>\n",
       "      <td>485.195021</td>\n",
       "      <td>1.012343</td>\n",
       "      <td>1-32753</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>183</td>\n",
       "      <td>75903</td>\n",
       "      <td>7.874317</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30858.0</td>\n",
       "      <td>8.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7657</th>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>163.645367</td>\n",
       "      <td>426.603834</td>\n",
       "      <td>1.000854</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>142.402685</td>\n",
       "      <td>426.939597</td>\n",
       "      <td>1.001250</td>\n",
       "      <td>1-32758</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>26</td>\n",
       "      <td>2239</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>11.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>138.235023</td>\n",
       "      <td>526.317972</td>\n",
       "      <td>1.003032</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>148.273543</td>\n",
       "      <td>519.044843</td>\n",
       "      <td>1.004296</td>\n",
       "      <td>1-32763</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>109</td>\n",
       "      <td>16648</td>\n",
       "      <td>2.935780</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8274.0</td>\n",
       "      <td>2.701754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>175.268852</td>\n",
       "      <td>713.537705</td>\n",
       "      <td>1.000060</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>183.513158</td>\n",
       "      <td>709.894737</td>\n",
       "      <td>1.000165</td>\n",
       "      <td>1-32767</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>82</td>\n",
       "      <td>7478</td>\n",
       "      <td>2.073171</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>2.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7660 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_return_realized_volatility  log_return2_realized_volatility  \\\n",
       "0                           0.004499                         0.006999   \n",
       "1                           0.001204                         0.002476   \n",
       "2                           0.002369                         0.004801   \n",
       "3                           0.002574                         0.003637   \n",
       "4                           0.001894                         0.003257   \n",
       "...                              ...                              ...   \n",
       "7655                        0.003723                         0.004996   \n",
       "7656                        0.010829                         0.012168   \n",
       "7657                        0.003135                         0.004268   \n",
       "7658                        0.003750                         0.005773   \n",
       "7659                        0.001681                         0.002399   \n",
       "\n",
       "      wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0             0.000388           0.000852         0.000176        -0.000151   \n",
       "1             0.000212           0.000394         0.000142        -0.000135   \n",
       "2             0.000331           0.000725         0.000197        -0.000198   \n",
       "3             0.000380           0.000860         0.000190        -0.000108   \n",
       "4             0.000254           0.000397         0.000191        -0.000109   \n",
       "...                ...                ...              ...              ...   \n",
       "7655          0.000330           0.000597         0.000157        -0.000118   \n",
       "7656          0.000403           0.000922         0.000159        -0.000125   \n",
       "7657          0.000243           0.000648         0.000141        -0.000132   \n",
       "7658          0.000199           0.000421         0.000190        -0.000231   \n",
       "7659          0.000104           0.000281         0.000121        -0.000121   \n",
       "\n",
       "      volume_imbalance_mean  total_volume_mean  wap_mean  \\\n",
       "0                134.894040         323.496689  1.003725   \n",
       "1                142.050000         411.450000  1.000239   \n",
       "2                141.414894         416.351064  0.999542   \n",
       "3                146.216667         435.266667  0.998832   \n",
       "4                123.846591         343.221591  0.999619   \n",
       "...                     ...                ...       ...   \n",
       "7655             125.013029         296.185668  1.000142   \n",
       "7656             254.006073         567.840081  1.007503   \n",
       "7657             163.645367         426.603834  1.000854   \n",
       "7658             138.235023         526.317972  1.003032   \n",
       "7659             175.268852         713.537705  1.000060   \n",
       "\n",
       "      log_return_realized_volatility_300  log_return2_realized_volatility_300  \\\n",
       "0                               0.002953                             0.004864   \n",
       "1                               0.000981                             0.002009   \n",
       "2                               0.001295                             0.003196   \n",
       "3                               0.001776                             0.002713   \n",
       "4                               0.001520                             0.002188   \n",
       "...                                  ...                                  ...   \n",
       "7655                            0.002212                             0.002954   \n",
       "7656                            0.008499                             0.009971   \n",
       "7657                            0.002108                             0.003184   \n",
       "7658                            0.002728                             0.004435   \n",
       "7659                            0.001190                             0.001566   \n",
       "\n",
       "      wap_balance_mean_300  price_spread_mean_300  bid_spread_mean_300  \\\n",
       "0                 0.000372               0.000822             0.000223   \n",
       "1                 0.000239               0.000353             0.000164   \n",
       "2                 0.000431               0.000689             0.000141   \n",
       "3                 0.000331               0.000833             0.000158   \n",
       "4                 0.000252               0.000425             0.000191   \n",
       "...                    ...                    ...                  ...   \n",
       "7655              0.000283               0.000617             0.000165   \n",
       "7656              0.000483               0.001082             0.000196   \n",
       "7657              0.000261               0.000625             0.000146   \n",
       "7658              0.000195               0.000410             0.000165   \n",
       "7659              0.000110               0.000292             0.000113   \n",
       "\n",
       "      ask_spread_mean_300  volume_imbalance_mean_300  total_volume_mean_300  \\\n",
       "0               -0.000162                 137.158273             294.928058   \n",
       "1               -0.000123                 135.513043             484.521739   \n",
       "2               -0.000249                 144.147059             455.235294   \n",
       "3               -0.000095                 144.698113             418.169811   \n",
       "4               -0.000120                  99.449438             407.584270   \n",
       "...                   ...                        ...                    ...   \n",
       "7655            -0.000104                 120.469231             322.284615   \n",
       "7656            -0.000129                 217.410788             485.195021   \n",
       "7657            -0.000146                 142.402685             426.939597   \n",
       "7658            -0.000240                 148.273543             519.044843   \n",
       "7659            -0.000118                 183.513158             709.894737   \n",
       "\n",
       "      wap_mean_300   row_id  trade_log_return_realized_volatility  \\\n",
       "0         1.003753      0-5                              0.002006   \n",
       "1         1.000397     0-11                              0.000901   \n",
       "2         0.998685     0-16                              0.001961   \n",
       "3         0.998436     0-31                              0.001561   \n",
       "4         0.999488     0-62                              0.000871   \n",
       "...            ...      ...                                   ...   \n",
       "7655      1.000130  1-32751                              0.001776   \n",
       "7656      1.012343  1-32753                              0.008492   \n",
       "7657      1.001250  1-32758                              0.001927   \n",
       "7658      1.004296  1-32763                              0.002856   \n",
       "7659      1.000165  1-32767                              0.001704   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40            3179   \n",
       "1                                       30            1289   \n",
       "2                                       25            2161   \n",
       "3                                       15            1962   \n",
       "4                                       22            1791   \n",
       "...                                    ...             ...   \n",
       "7655                                    49            3249   \n",
       "7656                                   183           75903   \n",
       "7657                                    26            2239   \n",
       "7658                                   109           16648   \n",
       "7659                                    82            7478   \n",
       "\n",
       "      trade_order_count_mean  trade_log_return_realized_volatility_300  \\\n",
       "0                   2.750000                                  0.001308   \n",
       "1                   1.900000                                  0.000587   \n",
       "2                   2.720000                                  0.001137   \n",
       "3                   3.933333                                  0.001089   \n",
       "4                   4.045455                                  0.000453   \n",
       "...                      ...                                       ...   \n",
       "7655                2.775510                                  0.001280   \n",
       "7656                7.874317                                  0.006310   \n",
       "7657                2.615385                                  0.001567   \n",
       "7658                2.935780                                  0.001919   \n",
       "7659                2.073171                                  0.001303   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                         21.0              1587.0   \n",
       "1                                         16.0               900.0   \n",
       "2                                         12.0              1189.0   \n",
       "3                                          9.0              1556.0   \n",
       "4                                         11.0              1219.0   \n",
       "...                                        ...                 ...   \n",
       "7655                                      23.0              1889.0   \n",
       "7656                                      88.0             30858.0   \n",
       "7657                                      11.0               980.0   \n",
       "7658                                      57.0              8274.0   \n",
       "7659                                      40.0              3505.0   \n",
       "\n",
       "      trade_order_count_mean_300  \n",
       "0                       2.571429  \n",
       "1                       2.250000  \n",
       "2                       3.166667  \n",
       "3                       5.111111  \n",
       "4                       4.909091  \n",
       "...                          ...  \n",
       "7655                    3.608696  \n",
       "7656                    8.136364  \n",
       "7657                    2.727273  \n",
       "7658                    2.701754  \n",
       "7659                    2.125000  \n",
       "\n",
       "[7660 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_stock_ids = [0,1]\n",
    "preprocessor(list_stock_ids, is_train = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814304b",
   "metadata": {},
   "source": [
    "## Preprocess Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e69d9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8570fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1ef5ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   41.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 46.9 ms, total: 1.1 s\n",
      "Wall time: 2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = preprocessor(list_stock_ids= train_ids, is_train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87546a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "train = train[['row_id','target']]\n",
    "df_train = train.merge(df_train, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fcc6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>log_return_realized_volatility_300</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>wap_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.004864</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target  log_return_realized_volatility  \\\n",
       "0    0-5  0.004136                        0.004499   \n",
       "1   0-11  0.001445                        0.001204   \n",
       "2   0-16  0.002168                        0.002369   \n",
       "3   0-31  0.002195                        0.002574   \n",
       "4   0-62  0.001747                        0.001894   \n",
       "\n",
       "   log_return2_realized_volatility  wap_balance_mean  price_spread_mean  \\\n",
       "0                         0.006999          0.000388           0.000852   \n",
       "1                         0.002476          0.000212           0.000394   \n",
       "2                         0.004801          0.000331           0.000725   \n",
       "3                         0.003637          0.000380           0.000860   \n",
       "4                         0.003257          0.000254           0.000397   \n",
       "\n",
       "   bid_spread_mean  ask_spread_mean  volume_imbalance_mean  total_volume_mean  \\\n",
       "0         0.000176        -0.000151             134.894040         323.496689   \n",
       "1         0.000142        -0.000135             142.050000         411.450000   \n",
       "2         0.000197        -0.000198             141.414894         416.351064   \n",
       "3         0.000190        -0.000108             146.216667         435.266667   \n",
       "4         0.000191        -0.000109             123.846591         343.221591   \n",
       "\n",
       "   wap_mean  log_return_realized_volatility_300  \\\n",
       "0  1.003725                            0.002953   \n",
       "1  1.000239                            0.000981   \n",
       "2  0.999542                            0.001295   \n",
       "3  0.998832                            0.001776   \n",
       "4  0.999619                            0.001520   \n",
       "\n",
       "   log_return2_realized_volatility_300  wap_balance_mean_300  \\\n",
       "0                             0.004864              0.000372   \n",
       "1                             0.002009              0.000239   \n",
       "2                             0.003196              0.000431   \n",
       "3                             0.002713              0.000331   \n",
       "4                             0.002188              0.000252   \n",
       "\n",
       "   price_spread_mean_300  bid_spread_mean_300  ask_spread_mean_300  \\\n",
       "0               0.000822             0.000223            -0.000162   \n",
       "1               0.000353             0.000164            -0.000123   \n",
       "2               0.000689             0.000141            -0.000249   \n",
       "3               0.000833             0.000158            -0.000095   \n",
       "4               0.000425             0.000191            -0.000120   \n",
       "\n",
       "   volume_imbalance_mean_300  total_volume_mean_300  wap_mean_300  \\\n",
       "0                 137.158273             294.928058      1.003753   \n",
       "1                 135.513043             484.521739      1.000397   \n",
       "2                 144.147059             455.235294      0.998685   \n",
       "3                 144.698113             418.169811      0.998436   \n",
       "4                  99.449438             407.584270      0.999488   \n",
       "\n",
       "   trade_log_return_realized_volatility  trade_seconds_in_bucket_count_unique  \\\n",
       "0                              0.002006                                  40.0   \n",
       "1                              0.000901                                  30.0   \n",
       "2                              0.001961                                  25.0   \n",
       "3                              0.001561                                  15.0   \n",
       "4                              0.000871                                  22.0   \n",
       "\n",
       "   trade_size_sum  trade_order_count_mean  \\\n",
       "0          3179.0                2.750000   \n",
       "1          1289.0                1.900000   \n",
       "2          2161.0                2.720000   \n",
       "3          1962.0                3.933333   \n",
       "4          1791.0                4.045455   \n",
       "\n",
       "   trade_log_return_realized_volatility_300  \\\n",
       "0                                  0.001308   \n",
       "1                                  0.000587   \n",
       "2                                  0.001137   \n",
       "3                                  0.001089   \n",
       "4                                  0.000453   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                      21.0              1587.0   \n",
       "1                                      16.0               900.0   \n",
       "2                                      12.0              1189.0   \n",
       "3                                       9.0              1556.0   \n",
       "4                                      11.0              1219.0   \n",
       "\n",
       "   trade_order_count_mean_300  \n",
       "0                    2.571429  \n",
       "1                    2.250000  \n",
       "2                    3.166667  \n",
       "3                    5.111111  \n",
       "4                    4.909091  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992dae6f",
   "metadata": {},
   "source": [
    "## Preprocess Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4c9e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(data_dir + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68014dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1586a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 182 µs, total: 10.6 ms\n",
      "Wall time: 80.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = preprocessor(list_stock_ids= test_ids, is_train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11ac8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.merge(df_test, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c2fd1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#stock_id target encoding\n",
    "df_train['stock_id'] = df_train['row_id'].apply(lambda x:int(x.split('-')[0]))\n",
    "df_test['stock_id'] = df_test['row_id'].apply(lambda x:int(x.split('-')[0]))\n",
    "\n",
    "stock_id_target_mean = df_train.groupby('stock_id')['target'].mean() \n",
    "df_test['stock_id_target_enc'] = df_test['stock_id'].map(stock_id_target_mean) # test_set\n",
    "\n",
    "#training\n",
    "tmp = np.repeat(np.nan, df_train.shape[0])\n",
    "kf = KFold(n_splits = 10, shuffle=True,random_state = 19911109)\n",
    "for idx_1, idx_2 in kf.split(df_train):\n",
    "    target_mean = df_train.iloc[idx_1].groupby('stock_id')['target'].mean()\n",
    "\n",
    "    tmp[idx_2] = df_train['stock_id'].iloc[idx_2].map(target_mean)\n",
    "df_train['stock_id_target_enc'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b88413",
   "metadata": {},
   "source": [
    "## Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0306ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fd02c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8165a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = (32,16,8,4,2)\n",
    "stock_embedding_size = 16\n",
    "\n",
    "cat_data = df_train['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(3,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='selu')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb7d285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=1e-05, patience=10, verbose=1,\n",
    "    mode='min', baseline=0.25)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=3, verbose=1,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1012414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 10s 29ms/step - loss: 1002.8080 - MSE: 0.0047 - val_loss: 0.1603 - val_MSE: 6.9978e-06\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1528 - MSE: 6.8439e-06 - val_loss: 0.1454 - val_MSE: 5.5185e-06\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1327 - MSE: 5.8025e-06 - val_loss: 0.1233 - val_MSE: 5.4021e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1120 - MSE: 4.7222e-06 - val_loss: 0.1030 - val_MSE: 3.6047e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0953 - MSE: 3.7639e-06 - val_loss: 0.1528 - val_MSE: 2.6250e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0938 - MSE: 3.1178e-06 - val_loss: 0.1211 - val_MSE: 2.3182e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0964 - MSE: 2.7229e-06 - val_loss: 0.1098 - val_MSE: 3.0784e-06\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0762 - MSE: 2.5507e-06 - val_loss: 0.0733 - val_MSE: 2.3425e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0740 - MSE: 2.5061e-06 - val_loss: 0.0725 - val_MSE: 2.5211e-06\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0714 - MSE: 2.4477e-06 - val_loss: 0.0717 - val_MSE: 2.2854e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0757 - MSE: 2.4205e-06 - val_loss: 0.0708 - val_MSE: 2.3208e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0783 - MSE: 2.4538e-06 - val_loss: 0.0707 - val_MSE: 2.3666e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0838 - MSE: 2.4595e-06 - val_loss: 0.0800 - val_MSE: 2.1866e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0812 - MSE: 2.4222e-06 - val_loss: 0.0749 - val_MSE: 2.2336e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0776 - MSE: 2.3835e-06 - val_loss: 0.0696 - val_MSE: 2.2245e-06\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0761 - MSE: 2.3693e-06 - val_loss: 0.0775 - val_MSE: 2.4838e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0887 - MSE: 2.3829e-06 - val_loss: 0.0993 - val_MSE: 2.0322e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1071 - MSE: 2.4581e-06 - val_loss: 0.0689 - val_MSE: 2.2109e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1203 - MSE: 2.5769e-06 - val_loss: 0.0787 - val_MSE: 2.1150e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0919 - MSE: 2.3948e-06 - val_loss: 0.1081 - val_MSE: 2.5068e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1324 - MSE: 2.5820e-06 - val_loss: 0.0805 - val_MSE: 2.0979e-06\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0715 - MSE: 2.3928e-06 - val_loss: 0.1060 - val_MSE: 2.8028e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0723 - MSE: 2.3790e-06 - val_loss: 0.0671 - val_MSE: 2.2040e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0777 - MSE: 2.2994e-06 - val_loss: 0.0667 - val_MSE: 2.1751e-06\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0695 - MSE: 2.2415e-06 - val_loss: 0.0690 - val_MSE: 2.3240e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0684 - MSE: 2.2435e-06 - val_loss: 0.0981 - val_MSE: 2.6930e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0750 - MSE: 2.2974e-06 - val_loss: 0.0676 - val_MSE: 2.2260e-06\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0678 - MSE: 2.2340e-06 - val_loss: 0.0663 - val_MSE: 2.1744e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0660 - MSE: 2.2426e-06 - val_loss: 0.0681 - val_MSE: 2.1792e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0683 - MSE: 2.2600e-06 - val_loss: 0.0681 - val_MSE: 2.1189e-06\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0705 - MSE: 2.2692e-06 - val_loss: 0.0663 - val_MSE: 2.1566e-06\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0679 - MSE: 2.2541e-06 - val_loss: 0.0659 - val_MSE: 2.1792e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0655 - MSE: 2.2589e-06 - val_loss: 0.0661 - val_MSE: 2.2229e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0657 - MSE: 2.2588e-06 - val_loss: 0.0659 - val_MSE: 2.2094e-06\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.2244e-06 - val_loss: 0.0660 - val_MSE: 2.2179e-06\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0657 - MSE: 2.2688e-06 - val_loss: 0.0660 - val_MSE: 2.1783e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0679 - MSE: 2.2455e-06 - val_loss: 0.0659 - val_MSE: 2.1885e-06\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0650 - MSE: 2.2808e-06 - val_loss: 0.0672 - val_MSE: 2.2758e-06\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0653 - MSE: 2.2385e-06 - val_loss: 0.0659 - val_MSE: 2.2033e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.2543e-06 - val_loss: 0.0659 - val_MSE: 2.2033e-06\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0658 - MSE: 2.2117e-06 - val_loss: 0.0659 - val_MSE: 2.1894e-06\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0658 - MSE: 2.2159e-06 - val_loss: 0.0659 - val_MSE: 2.1975e-06\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0658 - MSE: 2.2569e-06 - val_loss: 0.0659 - val_MSE: 2.1930e-06\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0675 - MSE: 2.2155e-06 - val_loss: 0.0659 - val_MSE: 2.1920e-06\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0670 - MSE: 2.2587e-06 - val_loss: 0.0659 - val_MSE: 2.1949e-06\n",
      "Epoch 46/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0653 - MSE: 2.1912e-06 - val_loss: 0.0659 - val_MSE: 2.1965e-06\n",
      "Epoch 47/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0651 - MSE: 2.2157e-06 - val_loss: 0.0659 - val_MSE: 2.1968e-06\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Epoch 00047: early stopping\n",
      "Fold 1 NN: 0.25662\n",
      "CV 2/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 9s 29ms/step - loss: 514.3864 - MSE: 0.0024 - val_loss: 0.2066 - val_MSE: 9.3185e-06\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1930 - MSE: 8.4251e-06 - val_loss: 0.1448 - val_MSE: 6.4837e-06\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1275 - MSE: 5.2275e-06 - val_loss: 0.1136 - val_MSE: 3.2947e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0969 - MSE: 3.4122e-06 - val_loss: 0.0959 - val_MSE: 3.2775e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0942 - MSE: 2.7809e-06 - val_loss: 0.1092 - val_MSE: 2.2774e-06\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1069 - MSE: 2.6319e-06 - val_loss: 0.1762 - val_MSE: 2.2882e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1926 - MSE: 2.9974e-06 - val_loss: 0.0745 - val_MSE: 2.5116e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.3117 - MSE: 3.5957e-06 - val_loss: 0.3393 - val_MSE: 2.5213e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.3309 - MSE: 3.7013e-06 - val_loss: 0.4637 - val_MSE: 2.9674e-06\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.3045 - MSE: 3.5813e-06 - val_loss: 0.1677 - val_MSE: 2.4748e-06\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0806 - MSE: 2.7609e-06 - val_loss: 0.0718 - val_MSE: 2.5304e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0708 - MSE: 2.5288e-06 - val_loss: 0.0703 - val_MSE: 2.4482e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0743 - MSE: 2.5729e-06 - val_loss: 0.0725 - val_MSE: 2.3402e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0726 - MSE: 2.5119e-06 - val_loss: 0.0703 - val_MSE: 2.4171e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0703 - MSE: 2.4021e-06 - val_loss: 0.0689 - val_MSE: 2.3909e-06\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0762 - MSE: 2.5284e-06 - val_loss: 0.0756 - val_MSE: 2.4022e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0761 - MSE: 2.4242e-06 - val_loss: 0.0833 - val_MSE: 2.6644e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0823 - MSE: 2.5560e-06 - val_loss: 0.0821 - val_MSE: 2.1772e-06\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0704 - MSE: 2.3750e-06 - val_loss: 0.0717 - val_MSE: 2.2661e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0673 - MSE: 2.3097e-06 - val_loss: 0.0698 - val_MSE: 2.3818e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0727 - MSE: 2.3131e-06 - val_loss: 0.0685 - val_MSE: 2.2853e-06\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0688 - MSE: 2.3550e-06 - val_loss: 0.0702 - val_MSE: 2.2182e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0706 - MSE: 2.3320e-06 - val_loss: 0.0693 - val_MSE: 2.3729e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0731 - MSE: 2.3604e-06 - val_loss: 0.0748 - val_MSE: 2.4720e-06\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0682 - MSE: 2.3499e-06 - val_loss: 0.0688 - val_MSE: 2.3745e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0670 - MSE: 2.2647e-06 - val_loss: 0.0675 - val_MSE: 2.2810e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0675 - MSE: 2.3533e-06 - val_loss: 0.0683 - val_MSE: 2.2849e-06\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0661 - MSE: 2.3171e-06 - val_loss: 0.0674 - val_MSE: 2.2886e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0668 - MSE: 2.3665e-06 - val_loss: 0.0684 - val_MSE: 2.2450e-06\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0658 - MSE: 2.3085e-06 - val_loss: 0.0681 - val_MSE: 2.3689e-06\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0670 - MSE: 2.3150e-06 - val_loss: 0.0670 - val_MSE: 2.3094e-06\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0648 - MSE: 2.2984e-06 - val_loss: 0.0671 - val_MSE: 2.2600e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0663 - MSE: 2.2738e-06 - val_loss: 0.0669 - val_MSE: 2.2996e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0647 - MSE: 2.2360e-06 - val_loss: 0.0669 - val_MSE: 2.2695e-06\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.3173e-06 - val_loss: 0.0668 - val_MSE: 2.2870e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0652 - MSE: 2.2764e-06 - val_loss: 0.0672 - val_MSE: 2.2599e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0655 - MSE: 2.2399e-06 - val_loss: 0.0676 - val_MSE: 2.2351e-06\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0662 - MSE: 2.2998e-06 - val_loss: 0.0672 - val_MSE: 2.2877e-06\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0655 - MSE: 2.3208e-06 - val_loss: 0.0669 - val_MSE: 2.2769e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0645 - MSE: 2.2556e-06 - val_loss: 0.0668 - val_MSE: 2.2751e-06\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0653 - MSE: 2.3124e-06 - val_loss: 0.0668 - val_MSE: 2.2962e-06\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0665 - MSE: 2.3133e-06 - val_loss: 0.0668 - val_MSE: 2.2794e-06\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.2295e-06 - val_loss: 0.0668 - val_MSE: 2.2824e-06\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0662 - MSE: 2.3899e-06 - val_loss: 0.0668 - val_MSE: 2.2819e-06\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0661 - MSE: 2.2793e-06 - val_loss: 0.0668 - val_MSE: 2.2821e-06\n",
      "Epoch 00045: early stopping\n",
      "Fold 2 NN: 0.25841\n",
      "CV 3/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 9s 28ms/step - loss: 40.3992 - MSE: 1.9211e-04 - val_loss: 0.1789 - val_MSE: 8.2093e-06\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1734 - MSE: 7.6932e-06 - val_loss: 0.1477 - val_MSE: 6.1212e-06\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1343 - MSE: 5.6863e-06 - val_loss: 0.0922 - val_MSE: 3.4013e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0867 - MSE: 3.1937e-06 - val_loss: 0.0740 - val_MSE: 2.7698e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0810 - MSE: 2.8079e-06 - val_loss: 0.0720 - val_MSE: 2.7827e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1270 - MSE: 3.1104e-06 - val_loss: 0.0696 - val_MSE: 2.7923e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0877 - MSE: 2.8810e-06 - val_loss: 0.0711 - val_MSE: 2.7235e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0767 - MSE: 2.8055e-06 - val_loss: 0.1179 - val_MSE: 3.4729e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0851 - MSE: 2.8236e-06 - val_loss: 0.1810 - val_MSE: 2.5954e-06\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0776 - MSE: 2.7896e-06 - val_loss: 0.0674 - val_MSE: 2.7676e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0713 - MSE: 2.6763e-06 - val_loss: 0.0672 - val_MSE: 2.7449e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0682 - MSE: 2.6410e-06 - val_loss: 0.0671 - val_MSE: 2.7167e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0707 - MSE: 2.7171e-06 - val_loss: 0.0709 - val_MSE: 2.5065e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0694 - MSE: 2.6706e-06 - val_loss: 0.0669 - val_MSE: 2.5129e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0716 - MSE: 2.6392e-06 - val_loss: 0.1055 - val_MSE: 2.3506e-06\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0739 - MSE: 2.5548e-06 - val_loss: 0.0659 - val_MSE: 2.5015e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0714 - MSE: 2.5351e-06 - val_loss: 0.0875 - val_MSE: 2.3082e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0783 - MSE: 2.5665e-06 - val_loss: 0.0655 - val_MSE: 2.4685e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0704 - MSE: 2.5432e-06 - val_loss: 0.1290 - val_MSE: 3.3004e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 0.0772 - MSE: 2.5186e-06 - val_loss: 0.0719 - val_MSE: 2.3775e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0842 - MSE: 2.5658e-06 - val_loss: 0.0684 - val_MSE: 2.4046e-06\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0659 - MSE: 2.5122e-06 - val_loss: 0.0659 - val_MSE: 2.5299e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0707 - MSE: 2.4585e-06 - val_loss: 0.0645 - val_MSE: 2.4421e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0685 - MSE: 2.4228e-06 - val_loss: 0.0645 - val_MSE: 2.4352e-06\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0648 - MSE: 2.4561e-06 - val_loss: 0.0647 - val_MSE: 2.3854e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 0.0648 - MSE: 2.4022e-06 - val_loss: 0.0654 - val_MSE: 2.3369e-06\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0637 - MSE: 2.4088e-06 - val_loss: 0.0640 - val_MSE: 2.3854e-06\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.4578e-06 - val_loss: 0.0640 - val_MSE: 2.3692e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0650 - MSE: 2.3490e-06 - val_loss: 0.0640 - val_MSE: 2.3649e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0668 - MSE: 2.4044e-06 - val_loss: 0.0641 - val_MSE: 2.3961e-06\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0654 - MSE: 2.3543e-06 - val_loss: 0.0639 - val_MSE: 2.3635e-06\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0645 - MSE: 2.3753e-06 - val_loss: 0.0639 - val_MSE: 2.3917e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0638 - MSE: 2.3711e-06 - val_loss: 0.0638 - val_MSE: 2.3787e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 0.0635 - MSE: 2.4236e-06 - val_loss: 0.0638 - val_MSE: 2.3615e-06\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0638 - MSE: 2.3478e-06 - val_loss: 0.0638 - val_MSE: 2.3591e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0634 - MSE: 2.3404e-06 - val_loss: 0.0638 - val_MSE: 2.3600e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0635 - MSE: 2.3743e-06 - val_loss: 0.0638 - val_MSE: 2.3780e-06\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0647 - MSE: 2.3142e-06 - val_loss: 0.0638 - val_MSE: 2.3602e-06\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0651 - MSE: 2.3236e-06 - val_loss: 0.0638 - val_MSE: 2.3671e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0650 - MSE: 2.3892e-06 - val_loss: 0.0638 - val_MSE: 2.3586e-06\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0639 - MSE: 2.3831e-06 - val_loss: 0.0638 - val_MSE: 2.3618e-06\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0676 - MSE: 2.3969e-06 - val_loss: 0.0638 - val_MSE: 2.3614e-06\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0636 - MSE: 2.3706e-06 - val_loss: 0.0638 - val_MSE: 2.3660e-06\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0647 - MSE: 2.3709e-06 - val_loss: 0.0638 - val_MSE: 2.3650e-06\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0639 - MSE: 2.4006e-06 - val_loss: 0.0638 - val_MSE: 2.3645e-06\n",
      "Epoch 46/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0631 - MSE: 2.3500e-06 - val_loss: 0.0638 - val_MSE: 2.3642e-06\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Epoch 47/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0647 - MSE: 2.3467e-06 - val_loss: 0.0638 - val_MSE: 2.3642e-06\n",
      "Epoch 48/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0645 - MSE: 2.2931e-06 - val_loss: 0.0638 - val_MSE: 2.3642e-06\n",
      "Epoch 49/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0638 - MSE: 2.3327e-06 - val_loss: 0.0638 - val_MSE: 2.3642e-06\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.023999907090456e-09.\n",
      "Epoch 00049: early stopping\n",
      "Fold 3 NN: 0.25255\n",
      "CV 4/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 9s 28ms/step - loss: 5131.6937 - MSE: 0.0244 - val_loss: 0.4656 - val_MSE: 2.1811e-05\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.4229 - MSE: 1.9651e-05 - val_loss: 0.3260 - val_MSE: 1.4697e-05\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.3075 - MSE: 1.3762e-05 - val_loss: 0.2732 - val_MSE: 1.1681e-05\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.2330 - MSE: 9.7028e-06 - val_loss: 0.1917 - val_MSE: 7.8605e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1912 - MSE: 7.0935e-06 - val_loss: 0.2004 - val_MSE: 5.4208e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.2045 - MSE: 5.9345e-06 - val_loss: 0.1537 - val_MSE: 4.6187e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.8359 - MSE: 7.9586e-06 - val_loss: 3.0337 - val_MSE: 1.4701e-05\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 1.5945 - MSE: 1.1376e-05 - val_loss: 1.2017 - val_MSE: 6.4944e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 7.2711 - MSE: 3.5767e-05 - val_loss: 0.3785 - val_MSE: 7.0311e-06\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.1304 - MSE: 4.7373e-06 - val_loss: 0.1025 - val_MSE: 4.4161e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1071 - MSE: 4.3219e-06 - val_loss: 0.1003 - val_MSE: 4.3343e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.1139 - MSE: 4.1985e-06 - val_loss: 0.1134 - val_MSE: 3.9048e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1146 - MSE: 3.9800e-06 - val_loss: 0.0966 - val_MSE: 4.0089e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.1162 - MSE: 3.8201e-06 - val_loss: 0.0976 - val_MSE: 3.7614e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1239 - MSE: 3.7676e-06 - val_loss: 0.0934 - val_MSE: 3.4570e-06\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1267 - MSE: 3.6120e-06 - val_loss: 0.1665 - val_MSE: 3.8099e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1200 - MSE: 3.4996e-06 - val_loss: 0.1181 - val_MSE: 4.0099e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1200 - MSE: 3.4391e-06 - val_loss: 0.1106 - val_MSE: 3.6595e-06\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0883 - MSE: 3.0883e-06 - val_loss: 0.1004 - val_MSE: 3.0800e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0914 - MSE: 3.0745e-06 - val_loss: 0.0863 - val_MSE: 3.0553e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0880 - MSE: 3.0741e-06 - val_loss: 0.0857 - val_MSE: 2.8983e-06\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0903 - MSE: 3.0823e-06 - val_loss: 0.0887 - val_MSE: 2.8322e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0893 - MSE: 3.0511e-06 - val_loss: 0.0933 - val_MSE: 2.9157e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0981 - MSE: 3.0337e-06 - val_loss: 0.0865 - val_MSE: 3.1140e-06\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0832 - MSE: 2.9573e-06 - val_loss: 0.0801 - val_MSE: 2.9139e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0830 - MSE: 2.9385e-06 - val_loss: 0.0841 - val_MSE: 3.0214e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0827 - MSE: 2.9231e-06 - val_loss: 0.0831 - val_MSE: 2.8829e-06\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0874 - MSE: 2.9875e-06 - val_loss: 0.0815 - val_MSE: 2.8299e-06\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0828 - MSE: 2.9309e-06 - val_loss: 0.0795 - val_MSE: 2.8982e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0804 - MSE: 2.9255e-06 - val_loss: 0.0818 - val_MSE: 2.8957e-06\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0814 - MSE: 2.8559e-06 - val_loss: 0.0795 - val_MSE: 2.9172e-06\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0814 - MSE: 2.9098e-06 - val_loss: 0.0798 - val_MSE: 2.8494e-06\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0809 - MSE: 2.9429e-06 - val_loss: 0.0794 - val_MSE: 2.8951e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0797 - MSE: 2.8687e-06 - val_loss: 0.0794 - val_MSE: 2.8793e-06\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0814 - MSE: 2.9050e-06 - val_loss: 0.0794 - val_MSE: 2.8748e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0784 - MSE: 2.8940e-06 - val_loss: 0.0814 - val_MSE: 2.9535e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0794 - MSE: 2.9134e-06 - val_loss: 0.0794 - val_MSE: 2.8769e-06\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0813 - MSE: 2.8668e-06 - val_loss: 0.0794 - val_MSE: 2.8672e-06\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0817 - MSE: 2.8686e-06 - val_loss: 0.0792 - val_MSE: 2.8635e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0820 - MSE: 2.8543e-06 - val_loss: 0.0792 - val_MSE: 2.8620e-06\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0805 - MSE: 2.9127e-06 - val_loss: 0.0792 - val_MSE: 2.8644e-06\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0808 - MSE: 3.0138e-06 - val_loss: 0.0793 - val_MSE: 2.8796e-06\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0797 - MSE: 2.8787e-06 - val_loss: 0.0793 - val_MSE: 2.8877e-06\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0826 - MSE: 2.8856e-06 - val_loss: 0.0792 - val_MSE: 2.8694e-06\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0801 - MSE: 2.9045e-06 - val_loss: 0.0792 - val_MSE: 2.8722e-06\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 46/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0791 - MSE: 2.8731e-06 - val_loss: 0.0792 - val_MSE: 2.8753e-06\n",
      "Epoch 47/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0810 - MSE: 2.9349e-06 - val_loss: 0.0792 - val_MSE: 2.8783e-06\n",
      "Epoch 48/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0790 - MSE: 2.8600e-06 - val_loss: 0.0793 - val_MSE: 2.8847e-06\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Epoch 49/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0785 - MSE: 2.9098e-06 - val_loss: 0.0793 - val_MSE: 2.8822e-06\n",
      "Epoch 50/100\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 0.0789 - MSE: 2.8216e-06 - val_loss: 0.0793 - val_MSE: 2.8804e-06\n",
      "Epoch 51/100\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 0.0789 - MSE: 2.8981e-06 - val_loss: 0.0793 - val_MSE: 2.8786e-06\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.023999907090456e-09.\n",
      "Epoch 00051: early stopping\n",
      "Fold 4 NN: 0.28152\n"
     ]
    }
   ],
   "source": [
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "target_name = 'target'\n",
    "\n",
    "n_folds = 4\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds = {}\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = ['stock_id','log_return_realized_volatility','log_return2_realized_volatility','trade_log_return_realized_volatility']\n",
    "\n",
    "df_train[pred_name] = 0\n",
    "df_test['target'] = 0\n",
    "\n",
    "df_train['trade_log_return_realized_volatility'] = df_train['trade_log_return_realized_volatility'].fillna(0)\n",
    "df_test['log_return_realized_volatility'] = df_test['log_return_realized_volatility'].fillna(0)\n",
    "df_test['log_return2_realized_volatility'] = df_test['log_return2_realized_volatility'].fillna(0)\n",
    "df_test['trade_log_return_realized_volatility'] = df_test['trade_log_return_realized_volatility'].fillna(0)\n",
    "\n",
    "\n",
    "for dev_index, val_index in kf.split(range(len(train))):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    #Bottleneck ? \n",
    "    X_train = df_train.loc[dev_index, features_to_consider]\n",
    "    y_train = df_train.loc[dev_index, target_name].values\n",
    "    X_test = df_train.loc[val_index, features_to_consider]\n",
    "    y_test = df_train.loc[val_index, target_name].values\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.metrics.mean_squared_error,\n",
    "        metrics=['MSE'],\n",
    "    )\n",
    "\n",
    "\n",
    "    num_data = X_train[['log_return_realized_volatility','log_return2_realized_volatility','trade_log_return_realized_volatility']]\n",
    "    cat_data = X_train['stock_id']\n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[['log_return_realized_volatility','log_return2_realized_volatility','trade_log_return_realized_volatility']]\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target, \n",
    "              sample_weight = 1/np.square(target),\n",
    "              batch_size=1024,\n",
    "              epochs=100,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test, 1/np.square(y_test)),\n",
    "              callbacks=[es, plateau],\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    df_test[target_name] += model.predict([df_test['stock_id'], df_test[['log_return_realized_volatility','log_return2_realized_volatility','trade_log_return_realized_volatility']]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaaa37",
   "metadata": {},
   "source": [
    "## Predict Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2bd4f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'time_id', 'row_id', 'log_return_realized_volatility',\n",
       "       'log_return2_realized_volatility', 'wap_balance_mean',\n",
       "       'price_spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n",
       "       'volume_imbalance_mean', 'total_volume_mean', 'wap_mean',\n",
       "       'log_return_realized_volatility_300',\n",
       "       'log_return2_realized_volatility_300', 'wap_balance_mean_300',\n",
       "       'price_spread_mean_300', 'bid_spread_mean_300', 'ask_spread_mean_300',\n",
       "       'volume_imbalance_mean_300', 'total_volume_mean_300', 'wap_mean_300',\n",
       "       'trade_log_return_realized_volatility',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_log_return_realized_volatility_300',\n",
       "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
       "       'trade_order_count_mean_300', 'stock_id_target_enc', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "473400dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'target', 'log_return_realized_volatility',\n",
       "       'log_return2_realized_volatility', 'wap_balance_mean',\n",
       "       'price_spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n",
       "       'volume_imbalance_mean', 'total_volume_mean', 'wap_mean',\n",
       "       'log_return_realized_volatility_300',\n",
       "       'log_return2_realized_volatility_300', 'wap_balance_mean_300',\n",
       "       'price_spread_mean_300', 'bid_spread_mean_300', 'ask_spread_mean_300',\n",
       "       'volume_imbalance_mean_300', 'total_volume_mean_300', 'wap_mean_300',\n",
       "       'trade_log_return_realized_volatility',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_log_return_realized_volatility_300',\n",
       "       'trade_seconds_in_bucket_count_unique_300', 'trade_size_sum_300',\n",
       "       'trade_order_count_mean_300', 'stock_id', 'stock_id_target_enc',\n",
       "       'pred_NN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33eb3fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.25662, 0.25841, 0.25255, 0.28152]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.000711\n",
       "1   0-32  0.000520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display\n",
    "\n",
    "\n",
    "df_test[target_name] = df_test[target_name]/n_folds\n",
    "\n",
    "score = round(rmspe(y_true = df_train[target_name].values, y_pred = df_train[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(df_test[['row_id', target_name]].head(2))\n",
    "df_test[['row_id', target_name]].to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
